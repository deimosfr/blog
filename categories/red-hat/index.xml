<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Red Hat on Deimosfr Blog</title>
    <link>https://deimosfr.github.io/blog/categories/red-hat/</link>
    <description>Recent content in Red Hat on Deimosfr Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 18 Jun 2016 07:44:11 +0000</lastBuildDate>
    
	<atom:link href="https://deimosfr.github.io/blog/categories/red-hat/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Do not waste time with grep anymore, use tag</title>
      <link>https://deimosfr.github.io/blog/2016/06/18/do-not-waste-time-with-grep-anymore-use-tag/</link>
      <pubDate>Sat, 18 Jun 2016 07:44:11 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2016/06/18/do-not-waste-time-with-grep-anymore-use-tag/</guid>
      <description>Long time since my last post. This one is not very technical post, but it&amp;rsquo;s a nice to have solution if you use grep usually. Are not you fed up to type vim  and search the line after a grep command ? If yes, this post is for you.
First of all, you may know that an alternative more user friendly to grep exist, called ag (perf comparison). I really like ag and grep, but something make me loose my time since several years and I&amp;rsquo;m pretty sure it&amp;rsquo;s your case too.</description>
    </item>
    
    <item>
      <title>Zero downtime upgrade with Ansible and HAProxy</title>
      <link>https://deimosfr.github.io/blog/2016/01/21/zero-downtime-upgrade-with-ansible-and-haproxy/</link>
      <pubDate>Thu, 21 Jan 2016 13:00:16 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2016/01/21/zero-downtime-upgrade-with-ansible-and-haproxy/</guid>
      <description>Some of you may not be familiar with the terms &amp;ldquo;Rolling upgrade&amp;rdquo; or &amp;ldquo;Rolling restart&amp;rdquo;. This is the action of upgrading or restarting a cluster without service interruption (alias zero downtime). In most cases, this is done node by node, but in fact it depends of the technology you&amp;rsquo;re managing and the number of active nodes in your cluster.
At Nousmotards we have several Java Spring Boot applications running. Restarting one application can take up to 1 min.</description>
    </item>
    
    <item>
      <title>Upgrading Ansible Consul Template role</title>
      <link>https://deimosfr.github.io/blog/2015/11/27/upgrading-ansible-consul-template-role/</link>
      <pubDate>Fri, 27 Nov 2015 21:34:03 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2015/11/27/upgrading-ansible-consul-template-role/</guid>
      <description>As I wanted to upgrade it and because it has been asked several time, I upgraded the consul-template Ansible role to manage official binaries (and upgrades). Here are the new vars:
consul_template_version: &amp;#39;0.11.0&amp;#39; consul_template_arch: &amp;#39;linux_amd64&amp;#39; consul_template_http_src: &amp;quot;https://github.com/hashicorp/consul-template/releases/download/v{{consul_template_version}}/consul_template_{{consul_template_version}}_{{consul_template_arch}}.zip&amp;quot;  You can of course find the role to Ansible Galaxy: https://galaxy.ansible.com/detail#/role/3451
I hope you&amp;rsquo;ll enjoy this new version :-)</description>
    </item>
    
    <item>
      <title>Generate changelog from git commits and integrate with Sphinxdoc</title>
      <link>https://deimosfr.github.io/blog/2015/02/11/generate-changelog-from-git-commits-and-integrate-with-sphinxdoc-2/</link>
      <pubDate>Wed, 11 Feb 2015 11:00:22 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2015/02/11/generate-changelog-from-git-commits-and-integrate-with-sphinxdoc-2/</guid>
      <description>For another personal project (that I can&amp;rsquo;t talk about for the moment ;-)), I wanted to have a Changelog file to get a better following of the infrastructure evolution (configuration management, scripts&amp;hellip;all under git). Of course the documentation is very important, but when you do not write it at the same time you&amp;rsquo;re building the infrastructure, it may be complex to remember each little things you&amp;rsquo;ve done. That&amp;rsquo;s why a Changelog can help to understand how the infrastructure has been built step by step.</description>
    </item>
    
    <item>
      <title>Offload SSL with HAProxy</title>
      <link>https://deimosfr.github.io/blog/2015/01/27/offload-ssl-with-haproxy/</link>
      <pubDate>Tue, 27 Jan 2015 11:00:18 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2015/01/27/offload-ssl-with-haproxy/</guid>
      <description>A few months ago, I already talked about offloading SSL with Nginx. I also wanted to try it with HAProxy which can be more interesting in some cases.
The good On HAProxy, the good thing is the simplicity to do it. First of all you need to have at least the version 1.5 of HAProxy so to get SSL support. Then you only need those lines to offload SSL:</description>
    </item>
    
    <item>
      <title>Simple EC2 snapshot released !</title>
      <link>https://deimosfr.github.io/blog/2015/01/20/simple-ec2-snapshot-released/</link>
      <pubDate>Tue, 20 Jan 2015 11:00:12 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2015/01/20/simple-ec2-snapshot-released/</guid>
      <description>For my company, I recently had to find a good solution to make Snapshots from Instance IDs or from tags on AWS. I made several searches but unfortunately didn&amp;rsquo;t find what I was searching for.
That&amp;rsquo;s why I started to make a tool to do this kind of job. It&amp;rsquo;s written in Python and requires the Boto library. Here is what you can do with Simple EC2 snapshots:
 Hot snapshots (by default) and Cold snapshots   Multiple instances snapshot in one line   Detection of doubles   Filters by tags (allowing wildcards) or by instance IDs   Credentials file multiple with profiles   Limit the number of snapshots   Restrict snapshots to data disks only   The tool is open source and can be downloaded on GitHub :-).</description>
    </item>
    
    <item>
      <title>Packer: build multiple images easily</title>
      <link>https://deimosfr.github.io/blog/2015/01/16/packer-build-multiple-images-easily/</link>
      <pubDate>Fri, 16 Jan 2015 11:00:52 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2015/01/16/packer-build-multiple-images-easily/</guid>
      <description>Packer is one of the tools I&amp;rsquo;ve used in the past to build VirtualBox boxes. You can find what I&amp;rsquo;ve done on my GitHub account.
For Smash project, I wanted to make a packer configuration to manage Docker and VirtualBox. I also wanted to call Ansible to build specific images for each needs. The goal is to be able to build cloud image ready to start, without any special dependencies. This because I need different usages:</description>
    </item>
    
    <item>
      <title>Vagrant: provision vms and containers with Ansible</title>
      <link>https://deimosfr.github.io/blog/2015/01/13/vagrant-provision-vms-and-containers-with-ansible/</link>
      <pubDate>Tue, 13 Jan 2015 11:00:15 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2015/01/13/vagrant-provision-vms-and-containers-with-ansible/</guid>
      <description>In the last post, I talked about how to manage Docker and VirtualBox with Vagrant. This post follows the last one, with the integration of Ansible as a provisioner. Once again, I&amp;rsquo;m using it for the Smash project.
With Ansible, I made several &amp;ldquo;group_vars&amp;rdquo; files containing custom and common information related to the used environment (dev, uat, staging&amp;hellip;). This helps to setup different kind of environment easily. Vagrant will help to build images with Ansible deployed inside.</description>
    </item>
    
    <item>
      <title>Vagrant: manage Docker &#43; VirtualBox easily</title>
      <link>https://deimosfr.github.io/blog/2015/01/08/vagrant-manage-docker-virtualbox-easily/</link>
      <pubDate>Thu, 08 Jan 2015 11:00:02 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2015/01/08/vagrant-manage-docker-virtualbox-easily/</guid>
      <description>As you may know, I&amp;rsquo;m using Vagrant for more than a year now with VirtualBox. Docker is a faster alternative that needs to be taken into consideration. Having the possibility to manage both of them with the same tool can be very interesting. For information, I mainly use it with VirtualBox because it&amp;rsquo;s any platform compatible and Docker because it&amp;rsquo;s perfect for a CI like Jenkins.
I recently talked about my implication into the Smash project.</description>
    </item>
    
    <item>
      <title>OpenStack Summit in Paris on Monday!</title>
      <link>https://deimosfr.github.io/blog/2014/11/01/openstack-summit-in-paris-on-monday/</link>
      <pubDate>Sat, 01 Nov 2014 11:00:56 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/11/01/openstack-summit-in-paris-on-monday/</guid>
      <description>OpenStack Summit will take place in Paris in 2 days! I&amp;rsquo;m excited to be able to participate. Big thanks to eNovance/RedHat for it!
To know more about the event, please follow the link.</description>
    </item>
    
    <item>
      <title>Automatic package creation, which one to choose?</title>
      <link>https://deimosfr.github.io/blog/2014/10/30/automatic-package-creation-which-one-to-choose/</link>
      <pubDate>Thu, 30 Oct 2014 11:00:00 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/10/30/automatic-package-creation-which-one-to-choose/</guid>
      <description>I&amp;rsquo;m currently developing a complete packaging stack based on Docker to easily make different kind of packages for several Linux distributions. This for MySecureShell project.
This stack will be used to build packages in destination of upstream Linux distribution packages. But I&amp;rsquo;d like to provide a simpler and faster way to create custom repositories mainly for Debian, Ubuntu, CentOS and Fedora. In addition if packages could be automatically created when a new tag is pushed to the GitHub account, it would be perfect.</description>
    </item>
    
    <item>
      <title>Yosemite and Refind: recover your Linux boot</title>
      <link>https://deimosfr.github.io/blog/2014/10/22/yosemite-and-refind-recover-your-linux-boot/</link>
      <pubDate>Wed, 22 Oct 2014 10:00:00 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/10/22/yosemite-and-refind-recover-your-linux-boot/</guid>
      <description>You may upgrade your Mac OS X version to Yosemite (10.10) and saw you dual boot with Linux not working anymore :-(.
That&amp;rsquo;s because Apple made changes and Refind is not yet ready for it. So here is the solution to get your dual boot half back. It won&amp;rsquo;t fully work as expected, but you&amp;rsquo;ll be able to boot to Linux with Refind and Mac OS X with the alt key.</description>
    </item>
    
    <item>
      <title>Tig: browse your Git repositories in curses</title>
      <link>https://deimosfr.github.io/blog/2014/10/16/tig-browse-your-git-repositories-in-curses/</link>
      <pubDate>Thu, 16 Oct 2014 10:00:39 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/10/16/tig-browse-your-git-repositories-in-curses/</guid>
      <description>A colleague talked to me about this tool this week and I felt in love. It helps to easily navigate into your git repository. You can have a look on last log and directly in the same interface the diff of the current commit. I&amp;rsquo;ve attached one screenshot to let you see how cool it is.
The are also a lot of other features but just for browsing purpose. You can&amp;rsquo;t update or make changes.</description>
    </item>
    
    <item>
      <title>Fig: use docker to create a containers’ stack</title>
      <link>https://deimosfr.github.io/blog/2014/10/14/fig-use-docker-to-create-a-containers-stack/</link>
      <pubDate>Tue, 14 Oct 2014 10:00:03 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/10/14/fig-use-docker-to-create-a-containers-stack/</guid>
      <description>Fig is a fast, isolated development environments using Docker. For some features, it can be compared to Vagrant where the Dockerfike is not enough powerful to build multiple instances.
For example, let&amp;rsquo;s say you want to test a new product version of a software like MediaWiki and you want to build the complete stack. So you may need to have several tools categories (depending of the usage):
 Web: Nginx, PHP-FPM, Varnish App Cahing: Redis Search: ElasticSearch  In Vagrant you can natively build 3 VM and interconnect them without the need of additional tool.</description>
    </item>
    
    <item>
      <title>FIO: Bench IO disks</title>
      <link>https://deimosfr.github.io/blog/2014/10/06/fio-bench-io-disks/</link>
      <pubDate>Mon, 06 Oct 2014 10:00:30 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/10/06/fio-bench-io-disks/</guid>
      <description>The first thing you generally want to do when you have any new Storage system like SSD, Disk arrays or a Cluster Ceph, is benching. You will want to know how can read and write throughput. FIO is able to do that for you, here is an example:
[global] ioengine=libaio invalidate=1 ramp_time=5 direct=1 size=5G runtime=300 time_based directory=/home [seq-read] rw=read bs=64K stonewall [rand-read] rw=randread bs=4K stonewall [seq-write] rw=write bs=64K stonewall [rand-write] rw=randwrite bs=4K stonewall  You then will have a good output of everything you need to know.</description>
    </item>
    
    <item>
      <title>Galera Innoptimizer: optimize tables without stress</title>
      <link>https://deimosfr.github.io/blog/2014/09/30/galera-innoptimizer-optimize-tables-without-stress/</link>
      <pubDate>Tue, 30 Sep 2014 10:00:13 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/09/30/galera-innoptimizer-optimize-tables-without-stress/</guid>
      <description>I recently been faced on a classical problem on InnoDB which is the fragmentation, but on Galera. InnoDB engine doesn&amp;rsquo;t defragment on the fly and requires optimize maintenance sometimes to free disk space. But on Galera, which is a fault tolerance and high availability solution, it&amp;rsquo;s a problem having tables locked by an optimize procedure. Until Galera doesn&amp;rsquo;t support TokuDB and only fully support InnoDB, we had (with a colleague (Kevin aka Vinek)) to find a solution.</description>
    </item>
    
    <item>
      <title>Nginx: enable HSTS (force SSL for users)</title>
      <link>https://deimosfr.github.io/blog/2014/09/18/nginx-enable-hsts-force-ssl-for-users/</link>
      <pubDate>Thu, 18 Sep 2014 10:00:21 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/09/18/nginx-enable-hsts-force-ssl-for-users/</guid>
      <description>I recently heard of HSTS which is a way to force users to come back to your website in SSL if they&amp;rsquo;ve already be to HTTPS once. It is simple, just add this line:
# HSTS (force users to come in SSL if they&amp;#39;ve already been once) add_header Strict-Transport-Security &amp;quot;max-age=31536000; includeSubdomains&amp;quot;;  If you want to have an overview of a complete configuration with it, look at the my wiki.</description>
    </item>
    
    <item>
      <title>Dnsmasq and dhclient: use a specific DNS for a specific domain</title>
      <link>https://deimosfr.github.io/blog/2014/08/07/dnsmasq-and-dhclient-use-a-specific-dns-for-a-specific-domain/</link>
      <pubDate>Thu, 07 Aug 2014 10:00:53 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/08/07/dnsmasq-and-dhclient-use-a-specific-dns-for-a-specific-domain/</guid>
      <description>My use case is specific but not isolated. When I&amp;rsquo;m at work, I&amp;rsquo;m connected to my VPN at home. I have a specific DNS at home for my domain in deimos.lan and this is very useful to avoid me to remind all the IP of the services I have.
Sometimes, I want to connect to a home service from the VPN, but my bookmarked links have my home DNS which are unknown from the DNS at work.</description>
    </item>
    
    <item>
      <title>I am now working at Red Hat :-)</title>
      <link>https://deimosfr.github.io/blog/2014/06/20/now-working-at-red-hat/</link>
      <pubDate>Fri, 20 Jun 2014 10:00:00 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/06/20/now-working-at-red-hat/</guid>
      <description>And the thing has finally happened! In recent years, the idea of ​​one day working at Red Hat pleases me.
As you may know, I&amp;rsquo;m working at eNovance and the news is: RedHat has acquires eNovance! So I belong now to Red Hat family :-). RedHat really wants to to have our OpenStack experience and I&amp;rsquo;m excited to work with other teams like Ceph (ex Inktank).
I really hope it will be an excellent adventure and will enjoy it.</description>
    </item>
    
    <item>
      <title>Docker 1.0 &amp; RedHat 7</title>
      <link>https://deimosfr.github.io/blog/2014/06/18/too-many-new-software-versions/</link>
      <pubDate>Wed, 18 Jun 2014 10:00:00 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/06/18/too-many-new-software-versions/</guid>
      <description>I really like this kind of news, new versions of docker and RedHat:
 Docker 1.0: this is the first stable version after more than one year of development. This version is production ready and I will start using it asap. RedHat 7: this is a good news as the version 6 started to be a little bit old now. What&amp;rsquo;s new?  MariaDB replace MySQL \o/ Docker integrated systemd XFS by default Kernel 3.</description>
    </item>
    
    <item>
      <title>PRM: automatic MySQL/MariaDB replication managment</title>
      <link>https://deimosfr.github.io/blog/2014/04/25/prm-automatic-mysqlmariadb-replication-managment/</link>
      <pubDate>Fri, 25 Apr 2014 10:00:38 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/04/25/prm-automatic-mysqlmariadb-replication-managment/</guid>
      <description>The Percona replication manager (PRM) is a framework using the Linux HA resource agent Pacemaker that manages replication and provides automatic failover. This covers the installation of the framework on a set of servers. The PRM framework is made of 4 components: Corosync, Pacemaker, the mysql resource agent and MySQL itself.
It&amp;rsquo;s easy to setup, better if you already know how to use Pacemaker and it works like a charm. In fact it setup a master and x slaves.</description>
    </item>
    
    <item>
      <title>Ccze: easily colorize your logs output</title>
      <link>https://deimosfr.github.io/blog/2014/03/28/eccza-easily-colorize-your-logs-output/</link>
      <pubDate>Fri, 28 Mar 2014 11:00:00 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/03/28/eccza-easily-colorize-your-logs-output/</guid>
      <description>Some of you will tell me that most utility is doing it as well. And that&amp;rsquo;s right, but with ccze you will be able to colorize everything with a pipe. For example when you play with a verbose service like Pacemaker, you need to get colorization if you want to win time. Here is an example:
tail -f /var/log/syslog | ccze -A  </description>
    </item>
    
    <item>
      <title>Ansible: the Puppet outsider!</title>
      <link>https://deimosfr.github.io/blog/2014/03/04/ansible-the-puppet-outsider/</link>
      <pubDate>Tue, 04 Mar 2014 11:00:36 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2014/03/04/ansible-the-puppet-outsider/</guid>
      <description>It&amp;rsquo;s been a while now that I&amp;rsquo;ve heard of Ansible but I only started playing with a week ago. You may certainly know that I&amp;rsquo;m a Puppet lover, but this solution is more powerful than Puppet in my opinion.
So I started to migrate my personal Puppet to Ansible just to play with. Here are the pros:
 No client needed on the clients, only SSH! It&amp;rsquo;s written in Python By default a lot of modules Not only a configuration management tool, it&amp;rsquo;s an orchestrator too!</description>
    </item>
    
    <item>
      <title>Iptables is going to be replaced by NFtables</title>
      <link>https://deimosfr.github.io/blog/2013/11/24/iptables-is-going-to-be-replaced-by-nftables/</link>
      <pubDate>Sun, 24 Nov 2013 11:00:38 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/11/24/iptables-is-going-to-be-replaced-by-nftables/</guid>
      <description>If you’re not aware that the next kernel version will replace iptables by nftables, it’s time to learn on how it works, what are the features, why the change and how to use it.
If like me, you love PF, you&amp;rsquo;ll be pleased to find a similar syntax on NFtables ! To have a good introduction on it, look at those slides :
  Kernel Recipes 2013 - Nftables, what motivations and what solutions  from Anne Nicolas</description>
    </item>
    
    <item>
      <title>Shell : back to directory command (bd)</title>
      <link>https://deimosfr.github.io/blog/2013/09/19/shell-back-to-directory-command-bd/</link>
      <pubDate>Thu, 19 Sep 2013 10:00:44 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/09/19/shell-back-to-directory-command-bd/</guid>
      <description>I recently read a post (on Korben&amp;rsquo;s blog) regarding a command called bd to go back to a directory from you current full path. It permits to do more than that !
In fact this is a simple shell script, but it really helps when you&amp;rsquo;re in a long subfolder list. For example if you reside in &amp;lsquo;/home/user/project/src/org/main/site/utils/file/reader/whatever&amp;rsquo; and want to change to &amp;lsquo;/home/user/project/test&amp;rsquo;, then try &amp;lsquo;bd p`/test.
If you want to see all the possibilities, you can look at the main site project.</description>
    </item>
    
    <item>
      <title>DRBD : advanced usages</title>
      <link>https://deimosfr.github.io/blog/2013/09/09/drbd-advanced-usages/</link>
      <pubDate>Mon, 09 Sep 2013 10:00:00 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/09/09/drbd-advanced-usages/</guid>
      <description>At my work, I taught a DRBD training for advanced usages at work. I produced some slides and I would like to share them :
 I hope it could help&amp;hellip;</description>
    </item>
    
    <item>
      <title>Awesome : autostart app on boot depending on connected screens</title>
      <link>https://deimosfr.github.io/blog/2013/09/01/awesome-autostart-app-on-boot-depending-on-connected-screens/</link>
      <pubDate>Sun, 01 Sep 2013 10:00:06 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/09/01/awesome-autostart-app-on-boot-depending-on-connected-screens/</guid>
      <description>Awesome is still my window manager and I still love it. With my laptop, I need to be able to quickly get my working environment when I power it on. The major problem I had was to avoid having the same opened windows at boot if I&amp;rsquo;m in the train, at work or at home. Of course there is no GPS in the laptop to detect my location, so I couldn&amp;rsquo;t set a rule for it.</description>
    </item>
    
    <item>
      <title>Puppet: start to write your own module</title>
      <link>https://deimosfr.github.io/blog/2013/08/30/puppet-start-to-write-your-own-module/</link>
      <pubDate>Fri, 30 Aug 2013 10:00:45 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/08/30/puppet-start-to-write-your-own-module/</guid>
      <description>I didn&amp;rsquo;t really play with Puppet since a long time and a lot of things have changed.
I&amp;rsquo;m currently writing a Puppet module for MySecureShell. And the thing is, it&amp;rsquo;s hard to quickly find the relevant information on how to build a module from scratch. I like to have experience return and what a chance when I saw a tweet regarding it, the same day as I started to write the module :-)</description>
    </item>
    
    <item>
      <title>PackStack : quickly deploy OpenStack for production</title>
      <link>https://deimosfr.github.io/blog/2013/08/08/packstack-quickly-deploy-openstack-for-production/</link>
      <pubDate>Thu, 08 Aug 2013 10:00:04 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/08/08/packstack-quickly-deploy-openstack-for-production/</guid>
      <description>Last week, I&amp;rsquo;ve assisted to a webinar organized by Puppet Labs. The talk was about PackStack which is a solution to deploy OpenStack in a production environment.
How does PackStack works ? Some of you may tell me that DevStack do the same thing. But I warn once again about DevStack which is absolutely not build for production usages ! PackStack is a bundle of current modules for OpenStack available on Puppet Forge.</description>
    </item>
    
    <item>
      <title>PuPHPet : speed up your Vagrant deployment</title>
      <link>https://deimosfr.github.io/blog/2013/08/06/puphpet-speed-up-your-vagrant-deployment/</link>
      <pubDate>Tue, 06 Aug 2013 10:00:00 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/08/06/puphpet-speed-up-your-vagrant-deployment/</guid>
      <description>Vagrant is a fast solution build on top of VirtualBox. I already talked about it in a previous post.
The thing is, you could do really more with Vagrant by adding Puppet manifests or Chef recipes in your Vagrant configuration file. For those who don&amp;rsquo;t often use one of those 2 softwares, it quickly could transform into a nightmare when they want to deploy softwares in addition of the OS.</description>
    </item>
    
    <item>
      <title>Book : Pro Git</title>
      <link>https://deimosfr.github.io/blog/2013/07/21/book-pro-git/</link>
      <pubDate>Sun, 21 Jul 2013 10:00:00 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/07/21/book-pro-git/</guid>
      <description>Git : have you ever tried to play with it ? For several years I&amp;rsquo;m working with that fantastic tool. Anyway the biggest problem is : if you don&amp;rsquo;t work day to day with Git, you need a memento or something similar (like my wiki 😉).
Also, if you use it for your personal usage, you&amp;rsquo;ll be lost when you will work with complex workflows. As I&amp;rsquo;m not a developer, I use Git to manage my etc configuration, my puppet manifests, my custom scripts&amp;hellip;so many basic usage that really help me to win time as a sysadmin.</description>
    </item>
    
    <item>
      <title>Weechat : a user friendly IRC client</title>
      <link>https://deimosfr.github.io/blog/2013/05/24/weechat-a-user-friendly-irc-client/</link>
      <pubDate>Fri, 24 May 2013 10:00:30 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/05/24/weechat-a-user-friendly-irc-client/</guid>
      <description>WeeChat is a fast, light and extensible chat client. It runs on many platforms (including Linux, BSD and Mac OS). I&amp;rsquo;m using it over a year and really love that client.
WeeChat is:
 modular: a lightweight core with plugins around multi-protocols: IRC and Jabber (other soon) extensible: C plugins and scripts (Perl, Python, Ruby, Lua, Tcl and Scheme) free software: released under GPLv3 license fully documented: user&amp;rsquo;s guide, API, FAQ,.</description>
    </item>
    
    <item>
      <title>Simulate a black hole for a domain with Postfix</title>
      <link>https://deimosfr.github.io/blog/2013/05/20/simulate-a-black-hole-for-a-domain-with-postfix/</link>
      <pubDate>Mon, 20 May 2013 10:00:17 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/05/20/simulate-a-black-hole-for-a-domain-with-postfix/</guid>
      <description>When you manage outgoing emails through SMTP, you may sometimes need to test if a service is able to send correctly emails and itself check that there were no issue during sending. You can create a black hole for a specific domain and Postfix will answer from the same manner as if it is ok. It also permit to test Postfix sending capacities on a server.
To get more informations on this, follow that link.</description>
    </item>
    
    <item>
      <title>Cpulimit : limit CPU usage</title>
      <link>https://deimosfr.github.io/blog/2013/05/18/cpulimit-limit-cpu-usage/</link>
      <pubDate>Sat, 18 May 2013 10:00:38 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/05/18/cpulimit-limit-cpu-usage/</guid>
      <description>In a sad scenario where an application is fully consuming CPU to limit it. To do so, you will need a magic command called Cpulimit that will help you to limit a PID to a desired percentage usage of your CPU.
I&amp;rsquo;ve wrote a little documentation on cpulimit.</description>
    </item>
    
    <item>
      <title>Copy-Queue : Un gestionnaire de queue pour cp et mv</title>
      <link>https://deimosfr.github.io/blog/2013/04/22/copy-queue-un-gestionnaire-de-queue-pour-cp-et-mv/</link>
      <pubDate>Mon, 22 Apr 2013 10:00:38 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/04/22/copy-queue-un-gestionnaire-de-queue-pour-cp-et-mv/</guid>
      <description>Cela faisait un bail que j&amp;rsquo;attendais un soft de ce type, à tel point que je pensais en développer un au cas ou je ne trouve pas mon bonheur. Et par hasard, je suis tombé sur Copy-Queue qui fait exactement ce que je veux. A savoir, en ligne de commande, je peux faire des cp et des mv avec une gestion de file d&amp;rsquo;attente.
J&amp;rsquo;ai fais un petit article pour sa mise en place.</description>
    </item>
    
    <item>
      <title>SOSreport : récupérer des informations sur une machine rapidement</title>
      <link>https://deimosfr.github.io/blog/2013/04/18/sosreport-recuperer-des-informations-sur-une-machine-rapidement/</link>
      <pubDate>Thu, 18 Apr 2013 10:00:45 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/04/18/sosreport-recuperer-des-informations-sur-une-machine-rapidement/</guid>
      <description>Aujourd&amp;rsquo;hui, à Linagora, je travaille dans une équipe de support dont je suis le leader technique. Seulement voilà, mes gars ne connaissent pas de solutions de reporting de machine. Du coup, lorsqu&amp;rsquo;on a un client chez qui on doit récupérer des données d&amp;rsquo;une machine de prod, il est bien pratique d&amp;rsquo;avoir toutes les données d&amp;rsquo;un coup et éviter les aller/retour avec celui ci.
Dans mon ancienne boite, j&amp;rsquo;utilisais pas mal le support RedHat et le sosreport est quelque chose que j&amp;rsquo;ai pas mal utilisé.</description>
    </item>
    
    <item>
      <title>Forcer un shell lors de logins LDAP</title>
      <link>https://deimosfr.github.io/blog/2013/04/04/forcer-un-shell-lors-de-logins-ldap/</link>
      <pubDate>Thu, 04 Apr 2013 10:00:13 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/04/04/forcer-un-shell-lors-de-logins-ldap/</guid>
      <description>J&amp;rsquo;ai récemment aidé un ancien collègue qui avait besoin d&amp;rsquo;une solution pour forcer des utilisateurs ayant déjà un shell LDAP à avoir un shell plus restreint de type lshell. La problématique est que si l&amp;rsquo;on change le shell au niveau LDAP, il faudra alors utiliser ce shell sur toutes les machines. Ce n&amp;rsquo;est donc tout simplement pas envisageable.
Par contre, il est possible de modifier les propriétés NSS lors du login :-).</description>
    </item>
    
    <item>
      <title>KVM : Suspendre ses guests à l’arrêt du host</title>
      <link>https://deimosfr.github.io/blog/2013/03/21/kvm-suspendre-ses-guests-a-larret-du-host/</link>
      <pubDate>Thu, 21 Mar 2013 11:00:33 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/03/21/kvm-suspendre-ses-guests-a-larret-du-host/</guid>
      <description>Pour faire suite à mon article précédent sur KVM en desktop, j&amp;rsquo;avais cherché comment suspendre les guests lorsque j’éteins ma machine, au lieu qu&amp;rsquo;ils soient arrêtés.
J&amp;rsquo;ai donc fais un petit article dessus :-)</description>
    </item>
    
    <item>
      <title>Optimisations SSD pour Linux</title>
      <link>https://deimosfr.github.io/blog/2013/03/03/optimisations-ssd-pour-linux/</link>
      <pubDate>Sun, 03 Mar 2013 11:00:04 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/03/03/optimisations-ssd-pour-linux/</guid>
      <description>Les SSD coûtent de moins en moins cher et leurs performances sont incroyables comparées a celles des disques classiques.
Pourtant, si on ne fait pas un peu de tuning pour les optimiser, on perd des performances (moins linéaires) avec le temps et on réduit surtout leurs durée de vie.
Récemment j&amp;rsquo;ai passé tous mes ordinateurs perso sous SSD et par chance au boulot j&amp;rsquo;ai pu être équipé d&amp;rsquo;une bête de course avec SSD également.</description>
    </item>
    
    <item>
      <title>2ème et dernier jour au FOSDEM !</title>
      <link>https://deimosfr.github.io/blog/2013/02/05/2eme-et-dernier-jour-au-fosdem-2/</link>
      <pubDate>Tue, 05 Feb 2013 11:00:24 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2013/02/05/2eme-et-dernier-jour-au-fosdem-2/</guid>
      <description>Avant d&amp;rsquo;attaquer le 2 ème jour, je vais finir sur le premier (la suite d&amp;rsquo;hier).
Un des supers sujet était Bind 10 que j&amp;rsquo;attendais avec impatience. Il n&amp;rsquo;y a malheureusement eu d&amp;rsquo;informations sur les nouveautés aidant a la HA. Cependant il a été totalement réécrit pour supporter + de 100 cores alors qu&amp;rsquo;aujourd&amp;rsquo;hui au delà de 6, il y a des problèmes de performances. On a également (et étrangement) un serveur DHCP qui est intégré a Bind.</description>
    </item>
    
    <item>
      <title>Puppet : slides de présentation</title>
      <link>https://deimosfr.github.io/blog/2012/12/15/2567/</link>
      <pubDate>Sat, 15 Dec 2012 11:00:03 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/12/15/2567/</guid>
      <description>J&amp;rsquo;ai récemment réalisé une présentation sur Puppet à mon taf pour mes collègues. A cet effet, j&amp;rsquo;ai créer des slides que j&amp;rsquo;ai partagé sur SlideShare. Si vous avez ce type de présentation en Français à faire, vous pouvez vous appuyer sur la mienne comme je l&amp;rsquo;ai fait sur d&amp;rsquo;autres :-)
La présentation est disponible en téléchargement sur slideshare ou Puppet Slides.</description>
    </item>
    
    <item>
      <title>News en vrac</title>
      <link>https://deimosfr.github.io/blog/2012/12/11/news-en-vrac-6/</link>
      <pubDate>Tue, 11 Dec 2012 11:00:33 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/12/11/news-en-vrac-6/</guid>
      <description>Voici quelques petites modifications récemment effectuées sur le wiki :
 Kernel : J&amp;rsquo;ai mis à jour la documentation pour la recompilation des kernels. Pas de gros changements, juste un petit rafraîchissement graphique. Bind) : Petits correctifs sur quelques erreurs minimes Nagios : Une petite erreur sur l&amp;rsquo;installation, j&amp;rsquo;avais oublié &amp;lsquo;install&amp;rsquo; dans apt-get (Merci Sandro) Awk : Ajout d&amp;rsquo;un exemple awk Mediawki : J&amp;rsquo;ai mis à jour la page pour quelques petits trucs qui ont changés avec la dernière mouture de Mediawiki  </description>
    </item>
    
    <item>
      <title>Mediawiki 1.20 et les URL courtes</title>
      <link>https://deimosfr.github.io/blog/2012/12/07/2548/</link>
      <pubDate>Fri, 07 Dec 2012 11:00:50 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/12/07/2548/</guid>
      <description>J&amp;rsquo;ai récemment passé mon Mediawiki en 1.20. J&amp;rsquo;ai eu quelques petits soucis avec l&amp;rsquo;URL rewriting et les short URL. En effet, dans cette nouvelle version, ils ont supprimé le $wgUsePathInfo qui a du coup complètement cassé mes redirections.
J&amp;rsquo;ai finalement réussi à retrouver mon URL short mais d&amp;rsquo;une autre manière que je vous partage ici.
Bonne lecture</description>
    </item>
    
    <item>
      <title>Gnome Shell : Ajouter une appli custom dans la liste des applis</title>
      <link>https://deimosfr.github.io/blog/2012/11/25/gnome-shell-ajouter-une-appli-custom-dans-la-liste-des-applis/</link>
      <pubDate>Sun, 25 Nov 2012 11:00:39 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/11/25/gnome-shell-ajouter-une-appli-custom-dans-la-liste-des-applis/</guid>
      <description>On peut dire que même si je suis sous Xfce, Gnome Shell me manque et j&amp;rsquo;ai commencé à repasser certaines de mes machines dessus. Xfce est encore un peu jeune à mon goût (gestion du multi écran mal intégré, maximiser les fenêtres ne fonctionne pas tous le temps&amp;hellip;)
Et donc pour ajouter une Application dans la liste des Applications sous Gnome Shell, il faut se le faire à la main malheureusement.</description>
    </item>
    
    <item>
      <title>OpenLDAP : La sauvegarde et restauration de schéma</title>
      <link>https://deimosfr.github.io/blog/2012/11/13/openldap-la-sauvegarde-restauration-de-schema/</link>
      <pubDate>Tue, 13 Nov 2012 11:00:50 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/11/13/openldap-la-sauvegarde-restauration-de-schema/</guid>
      <description>J&amp;rsquo;ai un peu galérer à trouver des documentations claires sur la sauvegarde et restauration de schéma avec configuration d&amp;rsquo;un OpenLDAP v3.
Je vous fais partager ceci toujours sur mon Wiki.</description>
    </item>
    
    <item>
      <title>OpenLDAP : les ldif trop complets</title>
      <link>https://deimosfr.github.io/blog/2012/11/09/openldap-les-ldif-trop-complets/</link>
      <pubDate>Fri, 09 Nov 2012 11:00:14 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/11/09/openldap-les-ldif-trop-complets/</guid>
      <description>Je viens d&amp;rsquo;apprendre qu&amp;rsquo;un export LDAP (LDIF) trop complet ne permet pas sa réimportation sous peine de se voir jeter l&amp;rsquo;erreur 19 à la gueule. En effet, il y a plusieurs champs qui ne doivent pas figurer dans un LDIF.
J&amp;rsquo;ai donc eu la chance de trouver des personnes a qui ce même problème est arrivé et j&amp;rsquo;ai donc fais un petit article pour parler de cette erreur sur laquelle j&amp;rsquo;ai passé 1h.</description>
    </item>
    
    <item>
      <title>OpenLDAP : Les versions de fichiers de conf</title>
      <link>https://deimosfr.github.io/blog/2012/11/03/openldap-les-versions-de-fichiers-de-conf/</link>
      <pubDate>Sat, 03 Nov 2012 11:00:20 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/11/03/openldap-les-versions-de-fichiers-de-conf/</guid>
      <description>Pour ceux qui avaient t&amp;rsquo;habitude de travailler sur d&amp;rsquo;anciennes configurations d&amp;rsquo;OpenLDAP (v1/v2), ou comme moi, ne font pas des installations tous les 4 matins, sachez que les fichiers de configurations ont changés et sont super casse pied à configurer maintenant à la main.
J&amp;rsquo;avais déjà observé ceci sur les Red Hat 6.3 et viens de le constater également sur une Debian 6. Donc pour configurer votre OpenLDAP v3, c&amp;rsquo;est devenu un tel casse tête qu&amp;rsquo;il y a des wizard pour l&amp;rsquo;aide à la mise en place&amp;hellip;et heureusement.</description>
    </item>
    
    <item>
      <title>Authentification SSO depuis Apache sur backend AD via Kerberos</title>
      <link>https://deimosfr.github.io/blog/2012/10/26/authentification-sso-depuis-apache-sur-backend-ad-kerberos/</link>
      <pubDate>Fri, 26 Oct 2012 10:00:05 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/10/26/authentification-sso-depuis-apache-sur-backend-ad-kerberos/</guid>
      <description>J&amp;rsquo;ai récemment aider un collègue sur la mise en place d&amp;rsquo;un SSO Apache sur un AD. J&amp;rsquo;ai trouvé ça techniquement joli, donc je vous ai fais une petite documentation que j&amp;rsquo;ai grossièrement pompée sur un autre site tellement je l&amp;rsquo;ai trouvé bien faites, et j&amp;rsquo;y ai fais quelques petites retouches. J&amp;rsquo;en ai profité pour mettre très légèrement à jour la documentation sur la mise en place d&amp;rsquo;un serveur Kerberos.
Pour la documentation sur l&amp;rsquo;Authentification SSO depuis Apache sur backend AD via Kerberos</description>
    </item>
    
    <item>
      <title>La gestion de la mémoire sous Linux</title>
      <link>https://deimosfr.github.io/blog/2012/09/26/la-gestion-de-la-memoire-sous-linux/</link>
      <pubDate>Wed, 26 Sep 2012 10:00:09 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/09/26/la-gestion-de-la-memoire-sous-linux/</guid>
      <description>Ceci est mon dernier post sur le fonctionnement de la mémoire sous Linux. Je parle de :
 Swap Des fuites mémoires Des dirty et clean page L&amp;rsquo;OOM Kill  Ca se passe ici.</description>
    </item>
    
    <item>
      <title>Les caches mémoire</title>
      <link>https://deimosfr.github.io/blog/2012/09/24/les-caches-memoire/</link>
      <pubDate>Mon, 24 Sep 2012 10:00:31 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/09/24/les-caches-memoire/</guid>
      <description>Cette fois ci, je me suis attaqué aux caches Kernel. J&amp;rsquo;ai donc fais une petite doc pour comprendre comment ça fonctionne, pour voir leurs états et savoir comment les optimiser.
Cliquez ici pour lire cet article.</description>
    </item>
    
    <item>
      <title>L’adressage mémoire et son allocation</title>
      <link>https://deimosfr.github.io/blog/2012/09/22/ladressage-memoire-son-allocation/</link>
      <pubDate>Sat, 22 Sep 2012 10:00:13 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/09/22/ladressage-memoire-son-allocation/</guid>
      <description>Voici un nouveau post sur l&amp;rsquo;allocation de la mémoire. J&amp;rsquo;y aborde l&amp;rsquo;UMA, le NUMA, le tuning du TLB etc&amp;hellip;
Ça vous aidera certainement à comprendre comment la mémoire fonctionne si vous n&amp;rsquo;avez pas idée de comment les échanges et les caches sont gérés.
Ca se passe sur le wiki.</description>
    </item>
    
    <item>
      <title>Optimiser les performances de Sabnzbd</title>
      <link>https://deimosfr.github.io/blog/2012/09/18/optimiser-les-performances-de-sabnzbd/</link>
      <pubDate>Tue, 18 Sep 2012 10:00:43 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/09/18/optimiser-les-performances-de-sabnzbd/</guid>
      <description>J&amp;rsquo;ai mis à jour l&amp;rsquo;article sur SABnzbd avec au menu du jour :
 Des optimisations de performances Utilisation des post scripts avec exemple  Comme toujours, j&amp;rsquo;espère que ça servira à d&amp;rsquo;autres et ça se passe sur le wiki.</description>
    </item>
    
    <item>
      <title>Latence des process et kernel timing</title>
      <link>https://deimosfr.github.io/blog/2012/09/16/latence-des-process-kernel-timing/</link>
      <pubDate>Sun, 16 Sep 2012 10:00:31 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/09/16/latence-des-process-kernel-timing/</guid>
      <description>Toujours dans mes articles d&amp;rsquo;optimisation, en voici un sur les latences et le cpu pinning. Je parle de :
 Taskset Cpuset IRQ balancing cpuspeed acpi  Voilà, il y a pas mal de choses à racconter là dessus alors si vous souhaitez en savoir plus, suivez le lien.</description>
    </item>
    
    <item>
      <title>Gestion des process et des schedulers sous Linux</title>
      <link>https://deimosfr.github.io/blog/2012/09/10/gestion-des-process-des-schedulers-sous-linux/</link>
      <pubDate>Mon, 10 Sep 2012 10:00:48 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/09/10/gestion-des-process-des-schedulers-sous-linux/</guid>
      <description>Toujours dans la continuité de l&amp;rsquo;amélioration des performances sous Linux, je parle cette fois ci des schedulers et la gestion des processus.
Ca se passe ici : Gestion des process et des schedulers</description>
    </item>
    
    <item>
      <title>Optimisation des filesystems extX et du RAID sous Linux</title>
      <link>https://deimosfr.github.io/blog/2012/09/08/optimisation-des-filesystems-extx-du-raid-sous-linux/</link>
      <pubDate>Sat, 08 Sep 2012 10:00:34 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/09/08/optimisation-des-filesystems-extx-du-raid-sous-linux/</guid>
      <description>Pour continuer sur le précédent article d&amp;rsquo;optimisation des disques dur, en voici un autre sur le filesystem extX et le RAID logiciel sous Linux.
J&amp;rsquo;explique comment gagner en performance sur les filesystems et plonge un peu dans les méchanismes de la gestion des différents filesystems avec le kernel.
Pour lire l&amp;rsquo;article, suivez le lien.</description>
    </item>
    
    <item>
      <title>Optimiser les performances des disques dur sur Linux</title>
      <link>https://deimosfr.github.io/blog/2012/08/31/optimiser-les-performances-des-disques-dur-sur-linux/</link>
      <pubDate>Fri, 31 Aug 2012 10:00:47 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/08/31/optimiser-les-performances-des-disques-dur-sur-linux/</guid>
      <description>Les disques dur physiques sont aujourd&amp;rsquo;hui ce qu&amp;rsquo;il y a de plus lent dans nos machines. Que ce soit les disques dur physique à plateaux ou bien même les SSD ! Mais il y a moyen d&amp;rsquo;optimiser selon les besoins des performances de ceux ci.
C&amp;rsquo;est pourquoi j&amp;rsquo;ai fais un article qui parle des bus, caches, elevators et options de queues. Pour le lire, c&amp;rsquo;est comme d&amp;rsquo;habitude sur le wiki.</description>
    </item>
    
    <item>
      <title>AutoSSH : reconnecter automatiquement un tunnel SSH</title>
      <link>https://deimosfr.github.io/blog/2012/08/15/autossh-reconnecter-automatiquement-tunnel-ssh/</link>
      <pubDate>Wed, 15 Aug 2012 10:00:11 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/08/15/autossh-reconnecter-automatiquement-tunnel-ssh/</guid>
      <description>Si comme moi vous avez un tunnel à maintenir en permanence, qu&amp;rsquo;en cas de déconnexion vous souhaitez une reconnexion automatique, il vous faut utiliser alors un outil tel que AutoSSH.
Allez voici la doc pour mettre rapidement ça en place pour ceux que ça intéresse.</description>
    </item>
    
    <item>
      <title>Mcollective : gérer une ferme de noeuds</title>
      <link>https://deimosfr.github.io/blog/2012/08/13/mcollective/</link>
      <pubDate>Mon, 13 Aug 2012 10:00:51 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/08/13/mcollective/</guid>
      <description>Vous vous rappelez peut être de mon fameux Puppet Push qui me permettait d&amp;rsquo;exécuter des puppet client sur des hosts choisis.
Mcollective fait la même chose, mais en mieux et propose pleins de fonctionnalités en plus. Bref, il vous permet de contrôler tout un tas de machines très facilement et s&amp;rsquo;intègre très bien à Puppet. C&amp;rsquo;est d&amp;rsquo;ailleurs aujourd&amp;rsquo;hui ce que j&amp;rsquo;utilise en production. Plutôt qu&amp;rsquo;un long discourt, je vous laisse voir ma doc sur Mcollective.</description>
    </item>
    
    <item>
      <title>Créer un package RPM depuis un tar</title>
      <link>https://deimosfr.github.io/blog/2012/08/11/creer-package-rpm-depuis-tar/</link>
      <pubDate>Sat, 11 Aug 2012 10:00:33 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/08/11/creer-package-rpm-depuis-tar/</guid>
      <description>Je sais que beaucoup d&amp;rsquo;entre vous auront déjà vu maintes et maintes fois ce genre de doc, mais sur le net je n&amp;rsquo;ai trouvé que des choses vieilles ou obsolète. Il a fallu fouiller pas mal pour trouver des infos plus ou moins à jour et jongler entre elles pour ce rendre compte vraiment de ce qu&amp;rsquo;il faut faire pour s&amp;rsquo;en sortir proprement.
J&amp;rsquo;ai donc fais une doc qui en 5 min vous permettra de faire des packages Red Hat.</description>
    </item>
    
    <item>
      <title>Puppet : installation du serveur (Master)</title>
      <link>https://deimosfr.github.io/blog/2012/07/28/puppet-installation-du-serveur/</link>
      <pubDate>Sat, 28 Jul 2012 10:00:14 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/07/28/puppet-installation-du-serveur/</guid>
      <description>J&amp;rsquo;ai mis à jour la documentation sur Puppet sur la partie installation et la configuration du serveur. Je prépare quelques autres mises à jour de cet article qui vous aideront j&amp;rsquo;espère, à mettre en place ce type de solution qui devient très très vite indispensable :-)
Voici la mise à jour de l&amp;rsquo;installation et la configuration du puppet master.</description>
    </item>
    
    <item>
      <title>Parted mon amour</title>
      <link>https://deimosfr.github.io/blog/2012/07/16/parted-mon-amour/</link>
      <pubDate>Mon, 16 Jul 2012 10:00:54 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/07/16/parted-mon-amour/</guid>
      <description>Oh oui parted c&amp;rsquo;est bien, ça gère l&amp;rsquo;alignement des disques, c&amp;rsquo;est scriptable, ça gère les volumes supérieur à 2Tb&amp;hellip;bref le kiffe !
Donc cooooooomme d&amp;rsquo;habitude, j&amp;rsquo;ai mis à jour le petit article sur Parted.</description>
    </item>
    
    <item>
      <title>Mais arrêtez vos renommage d’interfaces réseaux !!!</title>
      <link>https://deimosfr.github.io/blog/2012/07/14/mais-arretez-vos-renommage-dinterfaces-reseaux/</link>
      <pubDate>Sat, 14 Jul 2012 10:00:55 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/07/14/mais-arretez-vos-renommage-dinterfaces-reseaux/</guid>
      <description>Pourquoi tant de haine ? Sérieusement, je ne comprends toujours pas pourquoi Solaris et maintenant Red Hat nous poussent à ce que les interfaces réseaux possèdent le nom court du chipset des cartes. C&amp;rsquo;est tellement chiant lorsque l&amp;rsquo;on souhaite gérer un parc informatique de manière automatisée.
Bref, j&amp;rsquo;ai donc fais un petit article pour dire comment revenir à nos bonnes vieilles interfaces en ethX. C&amp;rsquo;est pas ici.</description>
    </item>
    
    <item>
      <title>BTRFS…enfin !</title>
      <link>https://deimosfr.github.io/blog/2012/07/12/btrfs-enfin/</link>
      <pubDate>Thu, 12 Jul 2012 10:00:06 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/07/12/btrfs-enfin/</guid>
      <description>Bon&amp;hellip;on est encore loin du compte par rapport au ZFS hein ! Mais par rapport à l&amp;rsquo;extX, c&amp;rsquo;est vraiment un pas de géant. Etant donné que la première version stable du BTRFS est sortie, je me suis dis qu&amp;rsquo;il était temps de faire un article là dessus.
Si vous avez envie de voir ce qu&amp;rsquo;est un filesystem avancé, je vous conseil fortement de commencer à vous y mettre car c&amp;rsquo;est l&amp;rsquo;avenir sous Linux.</description>
    </item>
    
    <item>
      <title>Kickstart : Gestion des groupes de packages</title>
      <link>https://deimosfr.github.io/blog/2012/06/18/kickstart-gestion-des-groupes-de-packages/</link>
      <pubDate>Mon, 18 Jun 2012 10:00:00 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/06/18/kickstart-gestion-des-groupes-de-packages/</guid>
      <description>La gestion des groupes de packages dans les kickstart c&amp;rsquo;est vraiment relou quant on tombe pas sur une doc claire. J&amp;rsquo;ai perdu un peu de temps dessus donc j&amp;rsquo;ai rajouté dans la doc initiale ces informations pour qu&amp;rsquo;en 2 sec vous puissiez déterminer le nom d&amp;rsquo;un groupe de packages à utiliser dans le kickstart.
Ca se passe ici.</description>
    </item>
    
    <item>
      <title>FSCK à chaud sur EXT3/4</title>
      <link>https://deimosfr.github.io/blog/2012/05/13/fsck-a-chaud-sur-ext34/</link>
      <pubDate>Sun, 13 May 2012 10:00:31 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/05/13/fsck-a-chaud-sur-ext34/</guid>
      <description>Ouuuuuuuu le titre est kiffant hein ! Toi aussi tu as des contraintes super chaude de disponibilité, tu n’as pas la chance d’avoir du ZFS sur ton OS du bien ou tu te dis que BTRFS c’est encore trop jeune et tu dois supporter de l’ext encore quelques temps ?
Alors ceci est fait pour toi !!! J&amp;rsquo;ai concocté un petit script (un peu sale oui je l&amp;rsquo;avoue, mais il a le mérite de bien fonctionner) que j&amp;rsquo;ai pomper sur une discussion Red Hat permettant donc de jouer avec les snapshot pour fsckiser (oui le verbe) à la volée tous les LV de type ext3 et 4 sur une machine !</description>
    </item>
    
    <item>
      <title>News en vrac</title>
      <link>https://deimosfr.github.io/blog/2012/05/03/news-en-vrac-4/</link>
      <pubDate>Thu, 03 May 2012 10:00:41 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/05/03/news-en-vrac-4/</guid>
      <description>Voici quelques petites modifications récemment effectuées sur le wiki :
Netcat : laisser le port d&amp;rsquo;écoute ouvert après une première connection
Bonding : Les options qu&amp;rsquo;il faut utiliser lorsque l&amp;rsquo;on a plusieurs bonding
Puppet : mise à jour de la documentation pour les versions les plus récentes</description>
    </item>
    
    <item>
      <title>Grub : kernel de secours</title>
      <link>https://deimosfr.github.io/blog/2012/05/01/1797/</link>
      <pubDate>Tue, 01 May 2012 10:00:01 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/05/01/1797/</guid>
      <description>Vous n&amp;rsquo;avez jamais rêver de booter sur un kernel qui fonctionne si un nouveau que vous venez d&amp;rsquo;installer crash ? Grub l&amp;rsquo;a fait :-)
Pour sa mise en place, c&amp;rsquo;est facile, quelques lignes par ci par là, rien à installer, c&amp;rsquo;est intégré depuis un moment d&amp;rsquo;ailleurs, mais on en entends pas souvent parler. Alors voilà une petite doc qui en parle.</description>
    </item>
    
    <item>
      <title>Kickstart Red Hat</title>
      <link>https://deimosfr.github.io/blog/2012/04/29/kickstart-red-hat/</link>
      <pubDate>Sun, 29 Apr 2012 10:00:12 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/04/29/kickstart-red-hat/</guid>
      <description>Le titre est un peu court et pas très drôle, mais je suis en manque d&amp;rsquo;inspiration en ce moment.
Sur Red Hat (comme sur à peu prêt n&amp;rsquo;importe quel OS d&amp;rsquo;ailleurs), il est possible de déployer rapidement et de façon complètement automatisée un Red Hat grâce au Kickstart. J&amp;rsquo;ai fais une petite documentation rapide ici.</description>
    </item>
    
    <item>
      <title>Toujours plus haut vers les étoiles</title>
      <link>https://deimosfr.github.io/blog/2012/04/05/toujours-plus-haut-vers-les-etoiles/</link>
      <pubDate>Thu, 05 Apr 2012 11:00:35 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/04/05/toujours-plus-haut-vers-les-etoiles/</guid>
      <description>Ca fait un moment que je taf sur cette doc, et vu qu&amp;rsquo;elle me parait interminable, je vais la poster tel quel, car elle permet de mettre en place une infrastructure Red Hat Satellite assez simplement et surtout rapidement.
Si j&amp;rsquo;ai le temps et le courage, je la poursuivrais pour rentrer un peu dans les détails, mais le but n&amp;rsquo;est pas de réécrire la documentation officielle&amp;hellip;juste faire gagner du temps. Vous pouvez cette documentation sur Red Hat Satellite ici.</description>
    </item>
    
    <item>
      <title>Fast and Reboot</title>
      <link>https://deimosfr.github.io/blog/2012/03/22/fast-and-reboot-18/</link>
      <pubDate>Thu, 22 Mar 2012 11:00:12 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/03/22/fast-and-reboot-18/</guid>
      <description>Reboot de ta machine en quelques secondes ça t’intéresse ? Kexec est fait pour toi mon ptit pot !
Tu colle des néons, une waste gate et 2 bombes de nitro et biiiiim tu reboot en quelques secondes ! Kexec va t&amp;rsquo;éviter de te taper touuuuuuuute la couche de reboot hardware qui prend toujours 10 piges sur les serveurs. Comment tu met ça en place dans ta caisse man ?</description>
    </item>
    
    <item>
      <title>Lé boundingue</title>
      <link>https://deimosfr.github.io/blog/2012/03/20/le-boundingue/</link>
      <pubDate>Tue, 20 Mar 2012 11:00:50 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/03/20/le-boundingue/</guid>
      <description>Toua vouloir en saortie dou té carte raizo oune daibi day batouarde y dé la toulayronce dé paoune ? Boua ya lou boundigue paour ça !
Tou trouvra la doc paour là.
Note : Cette doc existait déjà, mais je lui ai fait un changement de sexe une cure de jouvance et l&amp;rsquo;ai mise à jour pour Red Hat.</description>
    </item>
    
    <item>
      <title>News en vrac</title>
      <link>https://deimosfr.github.io/blog/2012/03/18/news-en-vrac-2/</link>
      <pubDate>Sun, 18 Mar 2012 11:00:15 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/03/18/news-en-vrac-2/</guid>
      <description>Quelques news en vrac :
 Mise à jour des confs LDAP clients Générer des UUID Petites mises à jour sur Sed &amp;amp; Awk Voir le contenu des packages RPM  &amp;nbsp;</description>
    </item>
    
    <item>
      <title>Lilou Dallas Multipath</title>
      <link>https://deimosfr.github.io/blog/2012/03/16/lilou-dallas-multipath/</link>
      <pubDate>Fri, 16 Mar 2012 11:00:30 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/03/16/lilou-dallas-multipath/</guid>
      <description>“Oui oui, elle sait ce que c’est un qu’un multipath”..bref, vous aussi, vous venez de vous faire votre serveur iSCSI flamboyant et vous vous dites que ce serait bien d’avoir plusieurs chemins pour accéder à votre serveur.
Évidemment, pourquoi les baies de disques FC feraient ça et pas nous ? Allez hop, tous les chemins mènent à Rome non ? Alors c&amp;rsquo;est parti pour une doc sur le multipathing.</description>
    </item>
    
    <item>
      <title>iSCSI mon mignon</title>
      <link>https://deimosfr.github.io/blog/2012/03/14/iscsi-mon-mignon/</link>
      <pubDate>Wed, 14 Mar 2012 11:00:02 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/03/14/iscsi-mon-mignon/</guid>
      <description>Vous n’avez pas les sous pour vous acheter une baie de disques FC et vous voulez jouer tout comme si c’était le cas ? La solution du pauvre est là ! iSCSI, j’te l’dis mon pti gars !
Voilà une documentation pour mettre un serveur iSCSI et s&amp;rsquo;y connecter avec des clients.</description>
    </item>
    
    <item>
      <title>Udev : le choix de son device</title>
      <link>https://deimosfr.github.io/blog/2012/03/12/udev-le-choix-de-son-device/</link>
      <pubDate>Mon, 12 Mar 2012 11:00:05 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/03/12/udev-le-choix-de-son-device/</guid>
      <description>Vous avez toujours entendu que Linux c’était génial, qu’on pouvait faire tout ce que l’on voulait dessus, tout changer, tout mdifier…et là peut être qu’en réfléchissant un peu, vous vous dites : “C’est vrai ! On peut tout modifier…mais peut être pas ce qu’il y a dans /dev ?!”.
Et bien si et on peut en faire des choses dans ce /dev ! Je vous ai donc concocté une petite documentation sur ce merveilleux udev qui vous permettra de lancer des scripts au branchement d&amp;rsquo;un périphérique, de modifier le nom d&amp;rsquo;un device qui apparait dans /dev, de renomer /dev en /mes_periph_de_batard et moulte modifications de la muerta !</description>
    </item>
    
    <item>
      <title>Proxychains : laissez moi sortir !!!</title>
      <link>https://deimosfr.github.io/blog/2012/02/28/proxychains-laissez-moi-sortir/</link>
      <pubDate>Tue, 28 Feb 2012 11:00:28 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/02/28/proxychains-laissez-moi-sortir/</guid>
      <description>Ahhhh les proxy au taf ou à l’école !!! C’est pénible ! Bref, il arrive parfois que l’on souhaites vraiment avoir accès temporairement à l’extérieur. Quelles que soient les commandes que vous utilisez vous aurez ou non la possibilité de configurer l’utilisation d’un proxy en modifiant un fichier de configuration, une variable de d’environnement etc…
L&amp;rsquo;intérêt de proxychains est que la configuration ne se fait qu&amp;rsquo;une seule fois, dans son propre fichier de configuration.</description>
    </item>
    
    <item>
      <title>Tmux Cheat Sheet</title>
      <link>https://deimosfr.github.io/blog/2012/02/24/tmux-cheat-sheet/</link>
      <pubDate>Fri, 24 Feb 2012 11:00:40 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/02/24/tmux-cheat-sheet/</guid>
      <description>Je ne me suis pas mis au LaTeX pour rien, j’avais pour idée de pondre une Cheat Sheet sur Tmux, vu que je n’en avais trouvé aucune sur le net.
J&amp;rsquo;ai donc mis à jour la documentation Tmux avec les Cheat Sheet en anglais et français.
Je les fournis également ici :
 Tmux French Cheat Sheet
 Tmux English Cheat Sheet
  N&amp;rsquo;hésitez pas à me faire un retour ou des propositions sur d&amp;rsquo;éventuels ajouts.</description>
    </item>
    
    <item>
      <title>A tout cassé ? Pani pwoblem !</title>
      <link>https://deimosfr.github.io/blog/2012/02/10/a-tout-casse-pani-pwoblem/</link>
      <pubDate>Fri, 10 Feb 2012 11:00:39 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/02/10/a-tout-casse-pani-pwoblem/</guid>
      <description>J’ai un collègue qui a fait une belle boulette (un chown -Rf mysql sur / !). Du coup la merde, il a fallu trouver une solution pour restaurer les droits.
Heureusement Red Hat à penser aux têtes en l&amp;rsquo;air et a mis dans la commande rpm les options *setperms et *setugids pour réparer les droits sur les packages installés. Bref de quoi réparer votre machine.
Donc si vous aussi vous avez boulétiser, sachez qu&amp;rsquo;une solution existe sur Red Hat.</description>
    </item>
    
    <item>
      <title>PAM access sur Red Hat</title>
      <link>https://deimosfr.github.io/blog/2012/01/30/pam-access-sur-red-hat/</link>
      <pubDate>Mon, 30 Jan 2012 11:00:58 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/01/30/pam-access-sur-red-hat/</guid>
      <description>J’ai mis à jour la documentation sur PAM access pour Red Hat. Je n’avais que la version Debian, et la doc sur Red Hat étant un peu mince là dessus, je l’ai ajouter à ma documentation déjà présente.</description>
    </item>
    
    <item>
      <title>Vous prendrez bien une adresse IP ?!</title>
      <link>https://deimosfr.github.io/blog/2012/01/26/vous-prendrez-bien-une-adresse-ip/</link>
      <pubDate>Thu, 26 Jan 2012 11:00:14 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/01/26/vous-prendrez-bien-une-adresse-ip/</guid>
      <description>J’ai mis à jour la documentation sur les serveurs DHCP. Pas de grosses modifs mais plutôt un ajout des confs Red Hat.</description>
    </item>
    
    <item>
      <title>Varnish : accélérez vos serveurs web</title>
      <link>https://deimosfr.github.io/blog/2012/01/14/varnish-accelerez-vos-serveurs-web/</link>
      <pubDate>Sat, 14 Jan 2012 11:00:53 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2012/01/14/varnish-accelerez-vos-serveurs-web/</guid>
      <description>Varnish est un serveur de cache très connu et utilisé pour accélérer les serveurs web. Je l&amp;rsquo;ai mis en place pour le blog et le wiki alors n&amp;rsquo;hésitez pas à me dire si vous trouvez que c&amp;rsquo;est plus rapide.
C&amp;rsquo;est rapide à mettre en place et j&amp;rsquo;ai fais une petite documentation comme à mon habitude.</description>
    </item>
    
    <item>
      <title>RHCE done :-)</title>
      <link>https://deimosfr.github.io/blog/2011/12/18/rhce-done/</link>
      <pubDate>Sun, 18 Dec 2011 14:19:20 +0000</pubDate>
      
      <guid>https://deimosfr.github.io/blog/2011/12/18/rhce-done/</guid>
      <description>J&amp;rsquo;ai repassé l&amp;rsquo;examen RHCE et l&amp;rsquo;ai eu cette fois ci. Pour rappel il faut 210 points, j&amp;rsquo;avais fais 208&amp;frasl;300 la dernière fois, et cette fois ci 286&amp;frasl;300.
J&amp;rsquo;aimerais bien dire : &amp;ldquo;En route vers RHCA maintenant !&amp;rdquo;, mais je dois avouer que la route va être longue, cher et parsemée d’embuches. Il va me falloir 5 autres certifs pour atteindre ce titre. Il y en a 2 que je pense avoir sans trop de difficultés (Cluter + Statellite) tandis que la RH442 (celle dont j&amp;rsquo;ai eu la formation cette semaine) me semble bien complexe.</description>
    </item>
    
  </channel>
</rss>